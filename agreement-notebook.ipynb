{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('agreementresults4.json', 'r') as f:\n",
    "\n",
    "    a = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Jiaao Chen', 'Kayleigh Butera', 'Kehinde Ajibade', 'Mohan', 'Mohan Dodda', 'Pranit Dodda', 'Sebine Lee', 'Sebinne Lee', 'Yun Zhang', 'ZBT', 'ZBT ', 'Zaid Bin Tariq', 'ajibadekehinde1@gmail.com Hi Mohan could you send me an email. I had some technical issues with my Upwork. ', 'check', 'diyi'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_2079'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['Kayleigh Butera']['testannotations'][-1]['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in a['Kayleigh Butera']['testannotations']:\n",
    "    #print(u.keys()) \n",
    "    if u['fname'] not in results_dict:\n",
    "        results_dict[u['fname']] = {}\n",
    "        \n",
    "    results_dict[u['fname']]['scores'] = [u['scores']]\n",
    "    results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in a['Sebinne Lee']['testannotations']:\n",
    "#     #print(u.keys()) \n",
    "#     if u['fname'] not in results_dict:\n",
    "#         results_dict[u['fname']] = {}\n",
    "        \n",
    "#     results_dict[u['fname']]['scores'] = [u['scores']]\n",
    "#     results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': [{'Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': {'Coverage': -1,\n",
       "    'Accuracy': -1,\n",
       "    'Overall Quality': -2,\n",
       "    'Coherence': 0,\n",
       "    'Concise': 0},\n",
       "   'philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': {'Overall Quality': -1,\n",
       "    'Coverage': -1,\n",
       "    'Coherence': 0,\n",
       "    'Accuracy': 0,\n",
       "    'Concise': 0},\n",
       "   'linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': {'Overall Quality': 0,\n",
       "    'Accuracy': 0,\n",
       "    'Concise': 0,\n",
       "    'Coverage': 0,\n",
       "    'Coherence': 0}},\n",
       "  {'Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': {'Coherence': 0,\n",
       "    'Concise': 0,\n",
       "    'Accuracy': -1,\n",
       "    'Coverage': -1,\n",
       "    'Overall Quality': -2},\n",
       "   'philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': {'Overall Quality': -1,\n",
       "    'Concise': 0,\n",
       "    'Accuracy': 0,\n",
       "    'Coverage': -1,\n",
       "    'Coherence': 0},\n",
       "   'linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': {'Coherence': 0,\n",
       "    'Concise': 0,\n",
       "    'Coverage': 0,\n",
       "    'Accuracy': 0,\n",
       "    'Overall Quality': 0}}],\n",
       " 'salientInfoAll': [[{'end': 55, 'start': 23, 'lineno': 0, 'text': 'hard'},\n",
       "   {'start': 44, 'text': 'the', 'end': 73, 'lineno': 1},\n",
       "   {'text': 'liar', 'start': 15, 'lineno': 2, 'end': 18},\n",
       "   {'end': 46, 'text': 'saw you ', 'start': 23, 'lineno': 2}],\n",
       "  [{'end': 80,\n",
       "    'lineno': 0,\n",
       "    'text': 'Sam, we are hard up for the everyday expenses. When can you find a job',\n",
       "    'start': 11},\n",
       "   {'start': 10, 'end': 28, 'text': \" I'm looking for it\", 'lineno': 1},\n",
       "   {'text': 'the market is hard up for jobs',\n",
       "    'lineno': 1,\n",
       "    'end': 73,\n",
       "    'start': 44},\n",
       "   {'end': 18, 'lineno': 2, 'text': ' liar', 'start': 14},\n",
       "   {'start': 23, 'lineno': 2, 'end': 46, 'text': 'saw you again in the inn'},\n",
       "   {'start': 55, 'lineno': 2, 'end': 76, 'text': \"you don't want to work\"}]]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['train_2079']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in a['Pranit Dodda']['testannotations']:\n",
    "#     #print(u.keys()) \n",
    "#     if u['fname'] not in results_dict:\n",
    "#         results_dict[u['fname']] = {}\n",
    "#         results_dict[u['fname']]['scores'] = [u['scores']]\n",
    "#         results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]\n",
    "#     else:\n",
    "\n",
    "#         results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "#         results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in a['Yun Zhang']['testannotations']:\n",
    "#     #print(u.keys()) \n",
    "#     if u['fname'] not in results_dict:\n",
    "#         results_dict[u['fname']] = {}\n",
    "#         results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]\n",
    "#     else:\n",
    "\n",
    "#         results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "#         results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])\n",
    "        \n",
    "# #     results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "# #     results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for u in a['Kehinde Ajibade']['testannotations']:\n",
    "#     #print(u.keys()) \n",
    "#     if u['fname'] not in results_dict:\n",
    "#         results_dict[u['fname']] = {}\n",
    "#         results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]\n",
    "#     else:\n",
    "\n",
    "#         results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "#         results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])\n",
    "        \n",
    "# #     results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "# #     results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in a['Kayleigh Butera']['testannotations']:\n",
    "#     #print(u.keys()) \n",
    "#     if u['fname'] not in results_dict:\n",
    "#         results_dict[u['fname']] = {}\n",
    "#         results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]\n",
    "#     else:\n",
    "\n",
    "#         results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "#         results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])\n",
    "        \n",
    "# #     results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "# #     results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in a['ZBT']['testannotations']:\n",
    "    #print(u.keys()) \n",
    "    if u['fname'] not in results_dict:\n",
    "        results_dict[u['fname']] = {}\n",
    "        results_dict[u['fname']]['salientInfoAll'] = [u['salientInfoAll']]\n",
    "    else:\n",
    "\n",
    "        results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "        results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])\n",
    "        \n",
    "#     results_dict[u['fname']]['scores'].append(u['scores'])\n",
    "#     results_dict[u['fname']]['salientInfoAll'].append(u['salientInfoAll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkInput(rate, n):\n",
    "    \"\"\" \n",
    "    Check correctness of the input matrix\n",
    "    @param rate - ratings matrix\n",
    "    @return n - number of raters\n",
    "    @throws AssertionError \n",
    "    \"\"\"\n",
    "    N = len(rate)\n",
    "    k = len(rate[0])\n",
    "    assert all(len(rate[i]) == k for i in range(k)), \"Row length != #categories)\"\n",
    "    #assert all(isinstance(rate[i][j], int) for i in range(N) for j in range(k)), \"Element not integer\" \n",
    "    assert all(sum(row) == n for row in rate), \"Sum of ratings != #raters)\"\n",
    "\n",
    "def fleissKappa(rate,n):\n",
    "    \"\"\" \n",
    "    Computes the Kappa value\n",
    "    @param rate - ratings matrix containing number of ratings for each subject per category \n",
    "    [size - N X k where N = #subjects and k = #categories]\n",
    "    @param n - number of raters   \n",
    "    @return fleiss' kappa\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(rate)\n",
    "    k = len(rate[0])\n",
    "    print(\"#raters = \", n, \", #subjects = \", N, \", #categories = \", k)\n",
    "    checkInput(rate, n)\n",
    "\n",
    "    #mean of the extent to which raters agree for the ith subject \n",
    "    PA = sum([(sum([i**2 for i in row])- n) / (n * (n - 1)) for row in rate])/N\n",
    "    print(\"PA = \", PA)\n",
    "    \n",
    "    # mean of squares of proportion of all assignments which were to jth category\n",
    "    PE = sum([j**2 for j in [sum([rows[i] for rows in rate])/(N*n) for i in range(k)]])\n",
    "    print(\"PE =\", PE)\n",
    "    \n",
    "    kappa = -float(\"inf\")\n",
    "    try:\n",
    "        kappa = (PA - PE) / (1 - PE)\n",
    "        kappa = float(\"{:.3f}\".format(kappa))\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Expected agreement = 1\")\n",
    "\n",
    "    print(\"Fleiss' Kappa =\", kappa)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#raters =  14 , #subjects =  10 , #categories =  5\n",
      "PA =  0.378021978021978\n",
      "PE = 0.21275510204081632\n",
      "Fleiss' Kappa = 0.21\n"
     ]
    }
   ],
   "source": [
    "rate = \\\n",
    "    [\n",
    "        [0,0,0,0,14],\n",
    "        [0,2,6,4,2],\n",
    "        [0,0,3,5,6],\n",
    "        [0,3,9,2,0],\n",
    "        [2,2,8,1,1],\n",
    "        [7,7,0,0,0],\n",
    "        [3,2,6,3,0],\n",
    "        [2,5,3,2,2],\n",
    "        [6,5,2,1,0],\n",
    "        [0,2,2,3,7]\n",
    "    ]\n",
    "kappa = fleissKappa(rate,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ZBT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5c/cjd772lx6jq731tvvscmmk9r0000gn/T/ipykernel_56636/696547697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZBT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'ZBT'"
     ]
    }
   ],
   "source": [
    "results_dict['ZBT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict['train_24']['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict['train_24']['scores'][0]['Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict['train_24']['scores'][1].keys()\n",
    "checkl = [2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060]\n",
    "checkl = [52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
    "checkl =  [54, 55, 56, 57, 58, 59, 60]\n",
    "checkl =  [52, 53, 54, 55, 56, 57, 58]\n",
    "checkl = [2052, 2053, 2054, 2055, 2056, 2057, 2058]#, 2059, 2060]\n",
    "checkl = [55, 56, 57, 58, 59, 60]\n",
    "checkl = [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008]\n",
    "checkl = [2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060]\n",
    "checkl = [2052, 2053, 2054, 2055, 2056, 2057, 2058, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]\n",
    "# checkl = [2000, 2001, 2002, 2003, 2004]\n",
    "check1 = set([i for i in range(2000, 2049)])-set([2040, 2041, 2037, 2036])\n",
    "check1 = set([i for i in range(2065, 2075)])-set([2067, 2072, 2071, 2066])\n",
    "check1 = [2075, 2076, 2077, 2078, 2079]\n",
    "\n",
    "# check1 = [2000, 2001, 2002, 2003, 2004]\n",
    "# check1 = [52, 53, 54, 55, 56, 57, 58, 59, 60] +[2000, 2001, 2002, 2003, 2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train_79'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5c/cjd772lx6jq731tvvscmmk9r0000gn/T/ipykernel_56636/1685312393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_79'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'train_79'"
     ]
    }
   ],
   "source": [
    "results_dict['train_79'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed train_52\n",
      "failed train_53\n",
      "failed train_54\n",
      "failed train_55\n",
      "failed train_56\n",
      "failed train_57\n",
      "failed train_58\n",
      "failed train_59\n",
      "failed train_60\n",
      "failed train_61\n",
      "failed train_2000\n",
      "failed train_2001\n",
      "failed train_2002\n",
      "failed train_2003\n",
      "failed train_2004\n",
      "failed train_2005\n",
      "failed train_2006\n",
      "failed train_2007\n",
      "failed train_2008\n",
      "failed train_2009\n",
      "failed train_2010\n",
      "failed train_2011\n",
      "failed train_2012\n",
      "failed train_2013\n",
      "failed train_2014\n",
      "failed train_2015\n",
      "failed train_2016\n",
      "failed train_2017\n",
      "failed train_2018\n",
      "failed train_2019\n",
      "failed train_2020\n",
      "failed train_2021\n",
      "failed train_2022\n",
      "failed train_2023\n",
      "failed train_2024\n",
      "failed train_2025\n",
      "failed train_2026\n",
      "failed train_2027\n",
      "failed train_2028\n",
      "failed train_2029\n",
      "failed train_2030\n",
      "failed train_2031\n",
      "failed train_2032\n",
      "failed train_2033\n",
      "failed train_2034\n",
      "failed train_2035\n",
      "failed train_2036\n",
      "failed train_2037\n",
      "failed train_2038\n",
      "failed train_2039\n",
      "failed train_2040\n",
      "failed train_2041\n",
      "failed train_2042\n",
      "failed train_2043\n",
      "failed train_2044\n",
      "failed train_2045\n",
      "failed train_2046\n",
      "failed train_2047\n",
      "failed train_2048\n",
      "failed train_2049\n",
      "failed train_2050\n",
      "failed train_2065\n",
      "failed train_2066\n",
      "failed train_2067\n",
      "failed train_2068\n",
      "failed train_2069\n",
      "failed train_2070\n",
      "failed train_2071\n",
      "failed train_2072\n",
      "failed train_2073\n",
      "failed train_2074\n",
      "train_2075 2\n",
      "train_2076 2\n",
      "train_2077 2\n",
      "train_2078 2\n",
      "train_2079 2\n",
      "failed train_2051\n",
      "failed train_2052\n",
      "failed train_2053\n",
      "failed train_2054\n",
      "failed train_2055\n",
      "failed train_2056\n",
      "failed train_2057\n",
      "failed train_2058\n",
      "failed train_2059\n",
      "failed train_2060\n",
      "failed train_2061\n",
      "failed train_2062\n",
      "failed train_2063\n",
      "failed train_2064\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for (u,v) in results_dict.items():\n",
    "    num = int(u.split('_')[1])\n",
    "    if num in check1:\n",
    "#         print(int(u.split('_')[1]), check1, int(u.split('_')[1]) in checkl, u)\n",
    "        instance_name = u+'_'\n",
    "        for k in v['scores']:\n",
    "            for (p, q) in k.items():\n",
    "                temp = instance_name+p\n",
    "                if temp not in scores:\n",
    "                    scores[temp] = []\n",
    "#                 if len(scores[temp])<2:\n",
    "                scores[temp].append(q)\n",
    "        if len(scores[temp])!=3:\n",
    "            print(u, len(scores[temp]))\n",
    "        else:\n",
    "            print('passed', u)\n",
    "    else:\n",
    "        print('failed', u)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_2075_linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': [{'Coherence': 0,\n",
       "   'Accuracy': -2,\n",
       "   'Coverage': -2,\n",
       "   'Concise': 1,\n",
       "   'Overall Quality': -2},\n",
       "  {'Coverage': -2,\n",
       "   'Overall Quality': -2,\n",
       "   'Accuracy': 0,\n",
       "   'Coherence': 0,\n",
       "   'Concise': 1}],\n",
       " 'train_2075_philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': [{'Coherence': 0,\n",
       "   'Coverage': -2,\n",
       "   'Overall Quality': -2,\n",
       "   'Concise': 1,\n",
       "   'Accuracy': -2},\n",
       "  {'Coverage': -2,\n",
       "   'Coherence': 0,\n",
       "   'Concise': 1,\n",
       "   'Overall Quality': -2,\n",
       "   'Accuracy': -1}],\n",
       " 'train_2075_Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': [{'Concise': -1,\n",
       "   'Coherence': 0,\n",
       "   'Overall Quality': 1,\n",
       "   'Coverage': 1,\n",
       "   'Accuracy': 0},\n",
       "  {'Overall Quality': 0,\n",
       "   'Accuracy': -1,\n",
       "   'Coherence': 0,\n",
       "   'Concise': 0,\n",
       "   'Coverage': 1}],\n",
       " 'train_2076_Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': [{'Coverage': -2,\n",
       "   'Coherence': 0,\n",
       "   'Overall Quality': 0,\n",
       "   'Concise': 1,\n",
       "   'Accuracy': 1},\n",
       "  {'Coverage': -1,\n",
       "   'Coherence': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Concise': 0,\n",
       "   'Overall Quality': -1}],\n",
       " 'train_2076_linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': [{'Overall Quality': -2,\n",
       "   'Coherence': 0,\n",
       "   'Accuracy': -1,\n",
       "   'Concise': 0,\n",
       "   'Coverage': -1},\n",
       "  {'Overall Quality': -2,\n",
       "   'Concise': 0,\n",
       "   'Coverage': -1,\n",
       "   'Accuracy': -1,\n",
       "   'Coherence': 0}],\n",
       " 'train_2076_philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': [{'Concise': 0,\n",
       "   'Overall Quality': 0,\n",
       "   'Coherence': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Coverage': -1},\n",
       "  {'Coherence': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Concise': 0,\n",
       "   'Coverage': 0,\n",
       "   'Overall Quality': 0}],\n",
       " 'train_2077_linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': [{'Accuracy': 1,\n",
       "   'Overall Quality': 1,\n",
       "   'Coverage': 0,\n",
       "   'Concise': 0,\n",
       "   'Coherence': 0},\n",
       "  {'Coverage': 1,\n",
       "   'Overall Quality': 2,\n",
       "   'Concise': 0,\n",
       "   'Coherence': 0,\n",
       "   'Accuracy': 1}],\n",
       " 'train_2077_philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': [{'Overall Quality': 1,\n",
       "   'Concise': 0,\n",
       "   'Accuracy': 1,\n",
       "   'Coverage': 0,\n",
       "   'Coherence': 0},\n",
       "  {'Coverage': 1,\n",
       "   'Coherence': 0,\n",
       "   'Accuracy': 1,\n",
       "   'Overall Quality': 2,\n",
       "   'Concise': 0}],\n",
       " 'train_2077_Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': [{'Concise': 0,\n",
       "   'Overall Quality': -2,\n",
       "   'Accuracy': -2,\n",
       "   'Coverage': 0,\n",
       "   'Coherence': 0},\n",
       "  {'Concise': 0,\n",
       "   'Overall Quality': -2,\n",
       "   'Accuracy': -2,\n",
       "   'Coverage': -2,\n",
       "   'Coherence': 0}],\n",
       " 'train_2078_Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': [{'Coverage': 2,\n",
       "   'Concise': -1,\n",
       "   'Accuracy': 0,\n",
       "   'Overall Quality': 1,\n",
       "   'Coherence': 0},\n",
       "  {'Concise': -2,\n",
       "   'Accuracy': 0,\n",
       "   'Coverage': 2,\n",
       "   'Coherence': 0,\n",
       "   'Overall Quality': 2}],\n",
       " 'train_2078_philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': [{'Coverage': -2,\n",
       "   'Accuracy': 2,\n",
       "   'Coherence': 0,\n",
       "   'Overall Quality': 0,\n",
       "   'Concise': 2},\n",
       "  {'Coherence': 0,\n",
       "   'Concise': 2,\n",
       "   'Coverage': -2,\n",
       "   'Overall Quality': -2,\n",
       "   'Accuracy': 1}],\n",
       " 'train_2078_linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': [{'Overall Quality': -1,\n",
       "   'Accuracy': 1,\n",
       "   'Concise': 2,\n",
       "   'Coherence': 0,\n",
       "   'Coverage': -2},\n",
       "  {'Coherence': 0,\n",
       "   'Concise': 2,\n",
       "   'Coverage': -2,\n",
       "   'Overall Quality': -2,\n",
       "   'Accuracy': 1}],\n",
       " 'train_2079_Salesforce/bart-large-xsum-samsum vs linydub/bart-large-samsum': [{'Coverage': -1,\n",
       "   'Accuracy': -1,\n",
       "   'Overall Quality': -2,\n",
       "   'Coherence': 0,\n",
       "   'Concise': 0},\n",
       "  {'Coherence': 0,\n",
       "   'Concise': 0,\n",
       "   'Accuracy': -1,\n",
       "   'Coverage': -1,\n",
       "   'Overall Quality': -2}],\n",
       " 'train_2079_philschmid/distilbart-cnn-12-6-samsum vs knkarthick/meeting-summary-samsum': [{'Overall Quality': -1,\n",
       "   'Coverage': -1,\n",
       "   'Coherence': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Concise': 0},\n",
       "  {'Overall Quality': -1,\n",
       "   'Concise': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Coverage': -1,\n",
       "   'Coherence': 0}],\n",
       " 'train_2079_linydub/bart-large-samsum vs knkarthick/meeting-summary-samsum': [{'Overall Quality': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Concise': 0,\n",
       "   'Coverage': 0,\n",
       "   'Coherence': 0},\n",
       "  {'Coherence': 0,\n",
       "   'Concise': 0,\n",
       "   'Coverage': 0,\n",
       "   'Accuracy': 0,\n",
       "   'Overall Quality': 0}]}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numannotators = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def cal_kappa(name):\n",
    "    coverage_scores = []\n",
    "\n",
    "    for (u,v) in scores.items():\n",
    "        temp = []\n",
    "        for k in v:\n",
    "            temp.append(k[name])\n",
    "        coverage_scores.append(temp)\n",
    "#     print(coverage_scores)\n",
    "    raters = np.zeros([len(scores), 5]).astype(int)\n",
    "    count = 0\n",
    "    for i in range(0, len(coverage_scores)):\n",
    "        for k in coverage_scores[i]:\n",
    "            raters[i][k+2]+=1\n",
    "#         if i<13:\n",
    "#             raters[i][0] = 1\n",
    "#             raters[i][1] = 1\n",
    "#         else:\n",
    "# #             num = 0\n",
    "#             num = random.randint(0, 4)\n",
    "#             l = random.sample(range(5), 1)\n",
    "#             num = l[0]\n",
    "#             raters[i][num] = 2\n",
    "        \n",
    "    print(raters)\n",
    "    kappa = fleissKappa(raters,numannotators)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-2, -2],\n",
       " [-2, -2],\n",
       " [1, 1],\n",
       " [-2, -1],\n",
       " [-1, -1],\n",
       " [-1, 0],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, -2],\n",
       " [2, 2],\n",
       " [-2, -2],\n",
       " [-2, -2],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [0, 0]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_scoress = []\n",
    "for (u,v) in scores.items():\n",
    "    temp = []\n",
    "    for k in v:\n",
    "        temp.append(k['Coverage'])\n",
    "    coverage_scoress.append(temp)\n",
    "coverage_scoress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(coverage_scoress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage_scoress = []\n",
    "# for (u,v) in scores.items():\n",
    "#     temp = []\n",
    "#     for k in v:\n",
    "#         temp.append(k['Coverage'])\n",
    "#     coverage_scoress.append(temp)\n",
    "# coverage_scoress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0]\n",
      " [2 0 0 0 0]\n",
      " [0 0 0 2 0]\n",
      " [1 1 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 1 1 0]\n",
      " [1 0 1 0 0]\n",
      " [0 0 0 0 2]\n",
      " [2 0 0 0 0]\n",
      " [2 0 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 2 0 0]]\n",
      "#raters =  2 , #subjects =  15 , #categories =  5\n",
      "PA =  0.6666666666666666\n",
      "PE = 0.24444444444444446\n",
      "Fleiss' Kappa = 0.559\n"
     ]
    }
   ],
   "source": [
    "cal_kappa('Coverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]]\n",
      "#raters =  2 , #subjects =  15 , #categories =  5\n",
      "PA =  1.0\n",
      "PE = 1.0\n",
      "Fleiss' Kappa = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5c/cjd772lx6jq731tvvscmmk9r0000gn/T/ipykernel_56636/1429482093.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  kappa = (PA - PE) / (1 - PE)\n"
     ]
    }
   ],
   "source": [
    "cal_kappa('Coherence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 2 0]\n",
      " [0 0 0 2 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 0 0 0 2]\n",
      " [0 0 0 0 2]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]]\n",
      "#raters =  2 , #subjects =  15 , #categories =  5\n",
      "PA =  0.8\n",
      "PE = 0.4111111111111111\n",
      "Fleiss' Kappa = 0.66\n"
     ]
    }
   ],
   "source": [
    "cal_kappa('Concise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 2 0]\n",
      " [2 0 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 2 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 0 0]]\n",
      "#raters =  2 , #subjects =  15 , #categories =  5\n",
      "PA =  0.6666666666666666\n",
      "PE = 0.2644444444444444\n",
      "Fleiss' Kappa = 0.547\n"
     ]
    }
   ],
   "source": [
    "cal_kappa('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0]\n",
      " [2 0 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 1 1 0 0]\n",
      " [2 0 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 1 1]\n",
      " [2 0 0 0 0]\n",
      " [0 0 0 1 1]\n",
      " [1 0 1 0 0]\n",
      " [1 1 0 0 0]\n",
      " [2 0 0 0 0]\n",
      " [0 2 0 0 0]\n",
      " [0 0 2 0 0]]\n",
      "#raters =  2 , #subjects =  15 , #categories =  5\n",
      "PA =  0.5333333333333333\n",
      "PE = 0.26000000000000006\n",
      "Fleiss' Kappa = 0.369\n"
     ]
    }
   ],
   "source": [
    "cal_kappa('Overall Quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
